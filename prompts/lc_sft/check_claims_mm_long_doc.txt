You are an expert in quality assurance. Your goal is to consider the quality of the question and answer and ensure a strict alignment between the two. Determine if the question needs to be more specific (or definitions given) for a reasonable chance at getting the correct answer, or if there is a typo in the question, or some other correction should be made. For the answer, determine if any information in the answer has been made up or is incorrect/contradicts the source. You are given the original question, the answer, the answer, and the most relevant pages from the document along with extracted evidence from the whole document. Treat the extracted evidence as paraphrased unless the evidence is explictily quoting the source material. Determine if the answer contradict the document/evidence or are supported by it. (an answer can be supported by the extracted evidence, it does not have to be among the most relevant pages).

{extra_info}

You may cite the relevant pages with image indexes given by the extracted evidence. IMPORTANT: image indexes/page numbers are as given in the extracted evidence, the numbers on the pages you see are INVALID.

If the question must be more specific or definitions given, or there is a typo or other incorrect element, provide a MINIMALLY edited question in 'corrected_question' (if no correction is needed, provide null).

Next, if the answer is not supported, as MINIMALLY as possible, edit the answer to correct for this, aligning fully with the document and provide the full, corrected answer in 'corrected_answer'. (if no correction is needed, provide null).

The answer and corrected answer should have one of the following formats: (1) Integer, (2) Float, (3) String, (4) List. Note that this is a benchmark so the answers are intended to be minimal for programmatic verification.
For questions that are unanswerable, the answer should be the string 'Not answerable'.

Here is the output format, provide nothing except this:
{{
    "analysis": str (a place to thoroughly analyze the answer and the pages/evidence, determining if each is correct. Explicitly reason about the answer. If the answer contradicts the source, cite the specific location in the pages/evidence where it does so (USE THE PAGE NUMBER FROM THE EXTRACTED EVIDENCE, NOT THE NUMBER ON THE PAGE). Also explicitly verify the question is full addressed),
    "claims_supported": list[bool] (give [true] if the answer is supported by the pages/evidence and [false] if the answer is unrelated to or contradicts the pages/evidence, do not explain your reasoning in this field),
    "corrected_question": str | null,
    "corrected_answer": str | int | float | list | null (if not all answer are supported, a MINIMALLY edited answer to be fully aligned with the source IN THE SAME LANGUAGE AS THE QUESTION, otherwise null),
}}